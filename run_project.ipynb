{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persian Text Generation (RNN vs. Transformer)\n",
    "\n",
    "This notebook runs the complete pipeline for the text generation project. It will:\n",
    "1.  Install requirements.\n",
    "2.  Download and preprocess the data.\n",
    "3.  Train the RNN (GRU) model.\n",
    "4.  Train the from-scratch Transformer model.\n",
    "5.  Generate sample text with both models.\n",
    "6.  Display the loss plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip data using the script\n",
    "# This requires your kaggle.json API key to be set up\n",
    "!bash scripts/download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing\n",
    "!python scripts/preprocess.py \\\n",
    "    --input_file 'data/raw/Persian-WikiText-1.txt' \\\n",
    "    --stop_words_file 'data/raw/Persian_Stop_Words.txt' \\\n",
    "    --output_file 'data/processed/processed_text.txt' \\\n",
    "    --vocab_file 'data/processed/vocab.json' \\\n",
    "    --min_freq 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train RNN (GRU) Model\n",
    "\n",
    "We will train the GRU model for 5 epochs. You can increase this for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train.py \\\n",
    "    --model_type rnn \\\n",
    "    --data_file 'data/processed/processed_text.txt' \\\n",
    "    --vocab_file 'data/processed/vocab.json' \\\n",
    "    --model_save_dir 'outputs/models/' \\\n",
    "    --plot_save_dir 'outputs/plots/' \\\n",
    "    --log_file 'logs/train_rnn.log' \\\n",
    "    --n_gram 3 \\\n",
    "    --batch_size 128 \\\n",
    "    --epochs 5 \\\n",
    "    --lr 0.001 \\\n",
    "    --embed_size 128 \\\n",
    "    --hidden_size 256 \\\n",
    "    --num_layers 2 \\\n",
    "    --dropout 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Transformer Model\n",
    "\n",
    "Now we train the from-scratch Transformer. We use a smaller n-gram context (n=2) and fewer layers to manage training time. Transformer models are data-hungry and benefit from longer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train.py \\\n",
    "    --model_type transformer \\\n",
    "    --data_file 'data/processed/processed_text.txt' \\\n",
    "    --vocab_file 'data/processed/vocab.json' \\\n",
    "    --model_save_dir 'outputs/models/' \\\n",
    "    --plot_save_dir 'outputs/plots/' \\\n",
    "    --log_file 'logs/train_transformer.log' \\\n",
    "    --n_gram 2 \\\n",
    "    --batch_size 128 \\\n",
    "    --epochs 5 \\\n",
    "    --lr 0.0005 \\\n",
    "    --embed_size 128 \\\n",
    "    --num_layers 2 \\\n",
    "    --num_heads 4 \\\n",
    "    --d_ff 256 \\\n",
    "    --dropout 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Text\n",
    "\n",
    "Let's see the results. We use Top-K sampling (k=10) to avoid repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generating with RNN (GRU) Model ---\")\n",
    "!python scripts/generate.py \\\n",
    "    --model_type rnn \\\n",
    "    --model_path 'outputs/models/rnn_best.pth' \\\n",
    "    --vocab_file 'data/processed/vocab.json' \\\n",
    "    --seed_text 'ویکی پدیا یک دانشنامه' \\\n",
    "    --n_gram 3 \\\n",
    "    --max_length 30 \\\n",
    "    --top_k 10 \\\n",
    "    --embed_size 128 \\\n",
    "    --hidden_size 256 \\\n",
    "    --num_layers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generating with Transformer Model ---\")\n",
    "!python scripts/generate.py \\\n",
    "    --model_type transformer \\\n",
    "    --model_path 'outputs/models/transformer_best.pth' \\\n",
    "    --vocab_file 'data/processed/vocab.json' \\\n",
    "    --seed_text 'ویکی پدیا یک دانشنامه' \\\n",
    "    --n_gram 2 \\\n",
    "    --max_length 30 \\\n",
    "    --top_k 10 \\\n",
    "    --embed_size 128 \\\n",
    "    --num_layers 2 \\\n",
    "    --num_heads 4 \\\n",
    "    --d_ff 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"RNN (GRU) Model Loss\")\n",
    "display(Image(filename='outputs/plots/rnn_loss.png'))\n",
    "\n",
    "print(\"Transformer Model Loss\")\n",
    "display(Image(filename='outputs/plots/transformer_loss.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
